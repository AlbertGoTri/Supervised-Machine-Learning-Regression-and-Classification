{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c770ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Python representations of the JSON Schema Test Suite tests.\n",
    "\"\"\"\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import suppress\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import field, frozen\n",
    "from referencing import Registry\n",
    "import referencing.jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378001fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Iterable, Mapping, Sequence\n",
    "\n",
    "    from referencing.jsonschema import Schema\n",
    "    import pyperf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688caf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema.validators import _VALIDATORS\n",
    "import jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC_REMOTE_URL = \"http://localhost:1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5082e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DELIMITERS = re.compile(r\"[\\W\\- ]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_suite():\n",
    "    root = os.environ.get(\"JSON_SCHEMA_TEST_SUITE\")\n",
    "    if root is not None:\n",
    "        return Path(root)\n",
    "\n",
    "    root = Path(jsonschema.__file__).parent.parent / \"json\"\n",
    "    if not root.is_dir():  # pragma: no cover\n",
    "        raise ValueError(\n",
    "            (\n",
    "                \"Can't find the JSON-Schema-Test-Suite directory. \"\n",
    "                \"Set the 'JSON_SCHEMA_TEST_SUITE' environment \"\n",
    "                \"variable or run the tests from alongside a checkout \"\n",
    "                \"of the suite.\"\n",
    "            ),\n",
    "        )\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25460b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@frozen\n",
    "class Suite:\n",
    "\n",
    "    _root: Path = field(factory=_find_suite)\n",
    "\n",
    "\n",
    "    def benchmark(self, runner: pyperf.Runner):  # pragma: no cover\n",
    "        for name, Validator in _VALIDATORS.items():\n",
    "            self.version(name=name).benchmark(\n",
    "                runner=runner,\n",
    "                Validator=Validator,\n",
    "            )\n",
    "\n",
    "    def version(self, name) -> Version:\n",
    "        Validator = _VALIDATORS[name]\n",
    "        uri: str = Validator.ID_OF(Validator.META_SCHEMA)  # type: ignore[assignment]\n",
    "        specification = referencing.jsonschema.specification_with(uri)\n",
    "\n",
    "        registry = Registry().with_contents(\n",
    "            remotes_in(root=self._root / \"remotes\", name=name, uri=uri),\n",
    "            default_specification=specification,\n",
    "        )\n",
    "        return Version(\n",
    "            name=name,\n",
    "            path=self._root / \"tests\" / name,\n",
    "            remotes=registry,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@frozen\n",
    "class Version:\n",
    "\n",
    "    _path: Path\n",
    "    _remotes: referencing.jsonschema.SchemaRegistry\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def benchmark(self, **kwargs):  # pragma: no cover\n",
    "        for case in self.cases():\n",
    "            case.benchmark(**kwargs)\n",
    "\n",
    "    def cases(self) -> Iterable[_Case]:\n",
    "        return self._cases_in(paths=self._path.glob(\"*.json\"))\n",
    "\n",
    "    def format_cases(self) -> Iterable[_Case]:\n",
    "        return self._cases_in(paths=self._path.glob(\"optional/format/*.json\"))\n",
    "\n",
    "    def optional_cases_of(self, name: str) -> Iterable[_Case]:\n",
    "        return self._cases_in(paths=[self._path / \"optional\" / f\"{name}.json\"])\n",
    "\n",
    "    def to_unittest_testcase(self, *groups, **kwargs):\n",
    "        name = kwargs.pop(\"name\", \"Test\" + self.name.title().replace(\"-\", \"\"))\n",
    "        methods = {\n",
    "            method.__name__: method\n",
    "            for method in (\n",
    "                test.to_unittest_method(**kwargs)\n",
    "                for group in groups\n",
    "                for case in group\n",
    "                for test in case.tests\n",
    "            )\n",
    "        }\n",
    "        cls = type(name, (unittest.TestCase,), methods)\n",
    "\n",
    "        # We're doing crazy things, so if they go wrong, like a function\n",
    "        # behaving differently on some other interpreter, just make them\n",
    "        # not happen.\n",
    "        with suppress(Exception):\n",
    "            cls.__module__ = _someone_save_us_the_module_of_the_caller()\n",
    "\n",
    "        return cls\n",
    "\n",
    "    def _cases_in(self, paths: Iterable[Path]) -> Iterable[_Case]:\n",
    "        for path in paths:\n",
    "            for case in json.loads(path.read_text(encoding=\"utf-8\")):\n",
    "                yield _Case.from_dict(\n",
    "                    case,\n",
    "                    version=self,\n",
    "                    subject=path.stem,\n",
    "                    remotes=self._remotes,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@frozen\n",
    "class _Case:\n",
    "\n",
    "    version: Version\n",
    "\n",
    "    subject: str\n",
    "    description: str\n",
    "    schema: Mapping[str, Any] | bool\n",
    "    tests: list[_Test]\n",
    "    comment: str | None = None\n",
    "    specification: Sequence[dict[str, str]] = ()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data, remotes, **kwargs):\n",
    "        data.update(kwargs)\n",
    "        tests = [\n",
    "            _Test(\n",
    "                version=data[\"version\"],\n",
    "                subject=data[\"subject\"],\n",
    "                case_description=data[\"description\"],\n",
    "                schema=data[\"schema\"],\n",
    "                remotes=remotes,\n",
    "                **test,\n",
    "            ) for test in data.pop(\"tests\")\n",
    "        ]\n",
    "        return cls(tests=tests, **data)\n",
    "\n",
    "    def benchmark(self, runner: pyperf.Runner, **kwargs):  # pragma: no cover\n",
    "        for test in self.tests:\n",
    "            runner.bench_func(\n",
    "                test.fully_qualified_name,\n",
    "                partial(test.validate_ignoring_errors, **kwargs),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remotes_in(\n",
    "    root: Path,\n",
    "    name: str,\n",
    "    uri: str,\n",
    ") -> Iterable[tuple[str, Schema]]:\n",
    "    # This messy logic is because the test suite is terrible at indicating\n",
    "    # what remotes are needed for what drafts, and mixes in schemas which\n",
    "    # have no $schema and which are invalid under earlier versions, in with\n",
    "    # other schemas which are needed for tests.\n",
    "\n",
    "    for each in root.rglob(\"*.json\"):\n",
    "        schema = json.loads(each.read_text())\n",
    "\n",
    "        relative = str(each.relative_to(root)).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if (\n",
    "            ( # invalid boolean schema\n",
    "                name in {\"draft3\", \"draft4\"}\n",
    "                and each.stem == \"tree\"\n",
    "            ) or\n",
    "            (  # draft<NotThisDialect>/*.json\n",
    "                \"$schema\" not in schema\n",
    "                and relative.startswith(\"draft\")\n",
    "                and not relative.startswith(name)\n",
    "            )\n",
    "        ):\n",
    "            continue\n",
    "        yield f\"{MAGIC_REMOTE_URL}/{relative}\", schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "@frozen(repr=False)\n",
    "class _Test:\n",
    "\n",
    "    version: Version\n",
    "\n",
    "    subject: str\n",
    "    case_description: str\n",
    "    description: str\n",
    "\n",
    "    data: Any\n",
    "    schema: Mapping[str, Any] | bool\n",
    "\n",
    "    valid: bool\n",
    "\n",
    "    _remotes: referencing.jsonschema.SchemaRegistry\n",
    "\n",
    "    comment: str | None = None\n",
    "\n",
    "    def __repr__(self):  # pragma: no cover\n",
    "        return f\"<Test {self.fully_qualified_name}>\"\n",
    "\n",
    "    @property\n",
    "    def fully_qualified_name(self):  # pragma: no cover\n",
    "        return \" > \".join(  # noqa: FLY002\n",
    "            [\n",
    "                self.version.name,\n",
    "                self.subject,\n",
    "                self.case_description,\n",
    "                self.description,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def to_unittest_method(self, skip=lambda test: None, **kwargs):\n",
    "        if self.valid:\n",
    "            def fn(this):\n",
    "                self.validate(**kwargs)\n",
    "        else:\n",
    "            def fn(this):\n",
    "                with this.assertRaises(jsonschema.ValidationError):\n",
    "                    self.validate(**kwargs)\n",
    "\n",
    "        fn.__name__ = \"_\".join(\n",
    "            [\n",
    "                \"test\",\n",
    "                _DELIMITERS.sub(\"_\", self.subject),\n",
    "                _DELIMITERS.sub(\"_\", self.case_description),\n",
    "                _DELIMITERS.sub(\"_\", self.description),\n",
    "            ],\n",
    "        )\n",
    "        reason = skip(self)\n",
    "        if reason is None or os.environ.get(\"JSON_SCHEMA_DEBUG\", \"0\") != \"0\":\n",
    "            return fn\n",
    "        elif os.environ.get(\"JSON_SCHEMA_EXPECTED_FAILURES\", \"0\") != \"0\":  # pragma: no cover  # noqa: E501\n",
    "            return unittest.expectedFailure(fn)\n",
    "        else:\n",
    "            return unittest.skip(reason)(fn)\n",
    "\n",
    "    def validate(self, Validator, **kwargs):\n",
    "        Validator.check_schema(self.schema)\n",
    "        validator = Validator(\n",
    "            schema=self.schema,\n",
    "            registry=self._remotes,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if os.environ.get(\"JSON_SCHEMA_DEBUG\", \"0\") != \"0\":  # pragma: no cover\n",
    "            breakpoint()  # noqa: T100\n",
    "        validator.validate(instance=self.data)\n",
    "\n",
    "    def validate_ignoring_errors(self, Validator):  # pragma: no cover\n",
    "        with suppress(jsonschema.ValidationError):\n",
    "            self.validate(Validator=Validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _someone_save_us_the_module_of_the_caller():\n",
    "    \"\"\"\n",
    "    The FQON of the module 2nd stack frames up from here.\n",
    "\n",
    "    This is intended to allow us to dynamically return test case classes that\n",
    "    are indistinguishable from being defined in the module that wants them.\n",
    "\n",
    "    Otherwise, trial will mis-print the FQON, and copy pasting it won't re-run\n",
    "    the class that really is running.\n",
    "\n",
    "    Save us all, this is all so so so so so terrible.\n",
    "    \"\"\"\n",
    "\n",
    "    return sys._getframe(2).f_globals[\"__name__\"]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
