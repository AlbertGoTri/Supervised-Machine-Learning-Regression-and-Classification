{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99400a95",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_uni import plt_intuition, plt_stationary, plt_update_onclick, soup_bowl\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d8053",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression.\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    \n",
    "    Returns\n",
    "        total_cost (float): The cost of using w,b as the parameters for linear regression\n",
    "               to fit the data points in x and y\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m = x.shape[0] \n",
    "    \n",
    "    cost_sum = 0 \n",
    "    for i in range(m): \n",
    "        f_wb = w * x[i] + b   \n",
    "        cost = (f_wb - y[i]) ** 2  \n",
    "        cost_sum = cost_sum + cost  \n",
    "    total_cost = (1 / (2 * m)) * cost_sum  \n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1.0, 2.0])           #(size in 1000 square feet)\n",
    "y_train = np.array([300.0, 500.0])           #(price in 1000s of dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165057e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_intuition(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef654e",
   "metadata": {},
   "source": [
    "Cost is minimized when ùë§=200, which matches results from the previous lab\n",
    "Because the difference between the target and pediction is squared in the cost equation, the cost increases rapidly when ùë§ is either too large or too small.\n",
    "Using the w and b selected by minimizing cost results in a line which is a perfect fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ab7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger Data Set\n",
    "x_train = np.array([1.0, 1.7, 2.0, 2.5, 3.0, 3.2])\n",
    "y_train = np.array([250, 300, 480,  430,   630, 730,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all') \n",
    "fig, ax, dyn_items = plt_stationary(x_train, y_train)\n",
    "updater = plt_update_onclick(fig, ax, x_train, y_train, dyn_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex Cost surface\n",
    "soup_bowl()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
